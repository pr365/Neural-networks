{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no Early Stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.914\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt1klEQVR4nO3deXxU9b3/8ddntmyELWFNCIsiyiZCiCCKWkVBW3FpFddWayle7e1ybcXb1m73tnb9WVdKLbWtVWq1KrdFQatUKqAgArJvsgQwCWvInsl8f398JzCEJEzCzJw5k8/z8ZjHzJxzZs4nk+Sdb77nnO9XjDEopZRyP4/TBSillIoNDXSllEoRGuhKKZUiNNCVUipFaKArpVSK8Dm149zcXDNgwACndq+UUq70wQcf7DfG9GhunWOBPmDAAFasWOHU7pVSypVEZGdL67TLRSmlUoQGulJKpQgNdKWUShGO9aErpVR71NfXU1xcTE1NjdOlxFV6ejr5+fn4/f6oX6OBrpRyleLiYrKzsxkwYAAi4nQ5cWGM4cCBAxQXFzNw4MCoXxdVl4uITBaRTSKyVURmNrP+myKyKnxbKyINItK9DfUrpVRUampqyMnJSdkwBxARcnJy2vxfyCkDXUS8wBPAFGAocLOIDI3cxhjzc2PMKGPMKOBB4F/GmINtqkQppaKUymHeqD1fYzQt9CJgqzFmuzGmDpgLTG1l+5uB59tcSZQ2fXKUXy7cxP6K2njtQimlXCmaQM8Ddkc8Lw4vO4mIZAKTgZdaWD9dRFaIyIqysrK21grAtrIKHntrqwa6UsoRhw8f5sknn2zz66666ioOHz4c+4IiRBPozbX7W5oV4zPAuy11txhjZhtjCo0xhT16NHvl6in13buAzWm3492/qV2vV0qp09FSoDc0NLT6uvnz59O1a9c4VWVFc5ZLMdAv4nk+sLeFbacRx+4WAI/XR0AaCNVrC10plXgzZ85k27ZtjBo1Cr/fT6dOnejTpw+rVq1i/fr1XHvttezevZuamhq++tWvMn36dOD4cCcVFRVMmTKFCy+8kCVLlpCXl8err75KRkbGadcWTaAvBwaLyEBgDza0b2m6kYh0AS4GbjvtqlohvnQADXSlFD/4v3Ws31se0/cc2rcz3/vMsBbXP/zww6xdu5ZVq1axaNEirr76atauXXvs9MI5c+bQvXt3qqurGTt2LDfccAM5OTknvMeWLVt4/vnn+e1vf8uNN97ISy+9xG23nX50njLQjTFBEbkPWAB4gTnGmHUiMiO8flZ40+uAhcaYytOuqhXiCwAQCmqgK6WcV1RUdMK54o8++igvv/wyALt372bLli0nBfrAgQMZNWoUAGPGjGHHjh0xqSWqC4uMMfOB+U2WzWry/BngmZhU1QqP37bQjQa6Uh1eay3pRMnKyjr2eNGiRbz55pssXbqUzMxMLrnkkmbPJU9LSzv22Ov1Ul1dHZNaXDeWi/gbu1xS+7JfpVRyys7O5ujRo82uO3LkCN26dSMzM5ONGzeybNmyhNbmukv/Pb7wXzZtoSulHJCTk8OECRMYPnw4GRkZ9OrV69i6yZMnM2vWLEaOHMmQIUMYN25cQmtzXaB7tctFKeWw5557rtnlaWlpvPbaa82ua+wnz83NZe3atceW33///TGry3VdLt6ABrpSSjXHdYEu4S4X0UBXSqkTuC7QfY0t9AYNdKWUiuS6QPcGGlvodQ5XopRSycV9gR4+KIq20JVS6gSuC3S/10ut8SEN2kJXSqlIrgt0n1eow49oC10p5YD2Dp8L8Mgjj1BVVRXjio5zX6B7PNShLXSllDOSOdBdd2GRzyvUagtdKeWQyOFzJ02aRM+ePXnhhReora3luuuu4wc/+AGVlZXceOONFBcX09DQwHe/+11KSkrYu3cvl156Kbm5ubz99tsxr819ge4R6owfT0hb6Ep1eK/NhE8+iu179h4BUx5ucXXk8LkLFy7kxRdf5P3338cYwzXXXMM777xDWVkZffv25R//+Adgx3jp0qULv/rVr3j77bfJzc2Nbc1hrutyERHq8OHRFrpSymELFy5k4cKFnHfeeYwePZqNGzeyZcsWRowYwZtvvskDDzzA4sWL6dKlS0LqcV0LHaBOAqRpC10p1UpLOhGMMTz44IN8+ctfPmndBx98wPz583nwwQe54ooreOihh+Jej+ta6ABB/HhC9U6XoZTqgCKHz73yyiuZM2cOFRUVAOzZs4fS0lL27t1LZmYmt912G/fffz8rV6486bXx4MoWer348WoLXSnlgMjhc6dMmcItt9zC+PHjAejUqRPPPvssW7du5Zvf/CYejwe/389TTz0FwPTp05kyZQp9+vSJy0FRMcbE/E2jUVhYaFasWNGu1y75wcX0y6il37cSO3i8Usp5GzZs4JxzznG6jIRo7msVkQ+MMYXNbe/KLpd6Ani1y0UppU4QVaCLyGQR2SQiW0VkZgvbXCIiq0RknYj8K7ZlniioXS5KKXWSU/ahi4gXeAKYBBQDy0VknjFmfcQ2XYEngcnGmF0i0jNO9QJQ7wngC+lpi0p1VMYYRMTpMuKqPd3h0bTQi4Ctxpjtxpg6YC4wtck2twB/M8bsChdS2uZK2qBWMggYnSRaqY4oPT2dAwcOtCvw3MIYw4EDB0hPT2/T66I5yyUP2B3xvBg4v8k2ZwF+EVkEZAO/Nsb8sekbich0YDpAQUFBmwqNVO9JI6AzFinVIeXn51NcXExZWZnTpcRVeno6+fn5bXpNNIHe3P81Tf80+oAxwGVABrBURJYZYzaf8CJjZgOzwZ7l0qZKI9R50kkzNRAKgceVx3WVUu3k9/sZOHCg02UkpWgCvRjoF/E8H9jbzDb7jTGVQKWIvAOcC2wmDuo94X9DgjUQyIzHLpRSynWiad4uBwaLyEARCQDTgHlNtnkVuEhEfCKSie2S2RDbUo+r92SEH8RvGEqllHKbU7bQjTFBEbkPWAB4gTnGmHUiMiO8fpYxZoOIvA6sAULA08aYtfEqut4bbqHXVUJWfEYtU0opt4nq0n9jzHxgfpNls5o8/znw89iV1rKGxkCvr07E7pRSyhVceUTxeJdLpbOFKKVUEnFloDd4GwNdW+hKKdXInYHuCwd6nR4UVUqpRu4M9GN96BroSinVyJWBHvKFzz3XQFdKqWPcGejaQldKqZO4MtAb/OEWuvahK6XUMa4MdOPTK0WVUqopVwa61+ejFr+9UlQppRTg0kD3eYSjJhNq4zd7tlJKuY07A93r4SgZUHPE6VKUUippuDLQ/R6h3GRqoCulVARXBrrP6+GIycLUlDtdilJKJQ1XBnrAZ7tcTM1hp0tRSqmk4cpA93s9lJss0Ba6Ukod48pAD/g8lJOJ1GqgK6VUI3cGuteetijBagjWOV2OUkolBXcGeriFDoC20pVSCnBroHu99sIi0FMXlVIqLKpAF5HJIrJJRLaKyMxm1l8iIkdEZFX49lDsSz3O75XjLXQ900UppYAoJokWES/wBDAJKAaWi8g8Y8z6JpsuNsZ8Og41niTg83DQdLZPKg8kYpdKKZX0ommhFwFbjTHbjTF1wFxganzLal3A66GMLvZJRYmTpSilVPSMgSPFUL4vLm9/yhY6kAfsjnheDJzfzHbjRWQ1sBe43xizrukGIjIdmA5QUFDQ9mrDAj4P+0040CtL2/0+SikVNw1BOLAF9q2GTz6CT9bY++pDcOE34PLvxXyX0QS6NLPMNHm+EuhvjKkQkauAV4DBJ73ImNnAbIDCwsKm7xE1v9dDDWkE/Z3wVWigK6UcVl8DpettaO9bDfvWQMlaCNbY9b506DUMhk6F3iOg/4S4lBFNoBcD/SKe52Nb4ccYY8ojHs8XkSdFJNcYsz82ZZ4o4LM9RTVpuXTSLhelVCLVHoVP1oZb3uEAL9sIoaBdn9YF+oyEsXdD75H2cc5g8EYTt6cnmj0sBwaLyEBgDzANuCVyAxHpDZQYY4yIFGH75uN2tPLEQNcWulIqTqoOhlvcq48H+IFtHOukyOoJfc6Fs660971HQrcBIM11bMTfKQPdGBMUkfuABYAXmGOMWSciM8LrZwGfBe4RkSBQDUwzxrS7S+VUAl4b6FVpuVC+MV67UUp1JOX7YN8q213SGN5HIg4fdi2wgT1ymm119zkXsns7Vm5zovofwBgzH5jfZNmsiMePA4/HtrSWNbbQyzP6wb6F9vJ/XyBRu1dKuV1jeO9dBXs/tI+Pdd8K5A6GgnHQe3q45T0CMrs7V2+U4t+pEwf+cAv9UHoBmBAc3mm/AUop1VRFGexdaYO78dYY3uKB3CFwxqegzyjoOwp6DYe0Tk5W3G6uDPTGFvqB9PCx2gNbNdCVUlB9OBzaK2HPStsCLy8OrxTo0SS8e4+AQJZj5caaKwPd77UHHPanhc9lL9sIQ6Y4WJFSKuHqq21/d2N47/kADm47vr77INtt0vc8yBtt+79d2vKOlisDvfGgaLlk22/a7uUOV6SUiquGoD3P+1jLeyWUrAfTYNdn94G8MTDqFhvefc+DjG7O1uwAVwa6iBDweqhvCEHBeNj8ur2k1qFThZRSMXa0BIqXh28rbIDXV9l16V2g72i48Ovh8B4Nnfs4W2+ScGWgg+12qQuGYMBFsOrP9hueN8bpspRSbRWstV0nkQF+ZJdd5/HbUwRH3wF5hTbAuw/SxlsLXBvoAZ/HBvqQyfabvvZvGuhKJTtj4PCu48FdvNye790QnnmsSz/IL4RxMyB/rO339qc7W7OLuDbQ/Y1dLhnd4MzL4aMX4fLvg9fvdGlKqUa1Ffask8gAbxxQz5dh+7rH3WPDO69Qu05Ok2sD/VgLHaDwTnjuNdjwfzD8emcLU6qjCoXsKcSRXSel6+y1IgDdz7CnDOYX2gDvNUwbYDHm3kD3eqhrCP+gnHm5HT/h/d9qoCuVKDVHTmx5F684PoNYWmfbBXrR/Ta88wtdcaWl27k30CNb6B4vFH4R3viuHW+49whni1Mq1RhjxzXZ9R7sWgq734OSddhBqgR6DrVDw+aPtbfcs8DjyimLXc3VgV7f2EIHOO82ePt/Yfnv4DOPOFaXUikh1GADe9cyG+C7lsHR8KjZgU42tC+ZCf3Oty3x9M7O1qsAFwe6P7LLBey/c8NvgDUvwKQf6g+YUm1RX22vtNy5NNwCfx/qjtp1nfOg/3joNw4KzoeewxIytrdqO9d+VwLeiC6XRoVftOekr/kLFH3JmcKUcoOachvaO/8NO5fYqy9D9XZdz6Ew8kZ70V7BOOjar/X3UknDtYGe5vdQWRk8cWHeaDvozorf29lC9OIDpayqg7bbZOe79rZvtT37xOOzV1qOvxf6XwD9ijrkJfOpwrWBnu7zUlPfcOJCERh9O/zjv+wPbN9RjtSmlOMqSm3Le+e79r7xAKY3zfZ/X3Q/DJhgH6fQaIMdnXsD3e+hpj508oph18PrD8LquRroquM4WgI7FtvbziWwf7Nd7s+0By4v/bYN8L6j9crLFObiQG+mhQ724OiQKfDRX+GKH+mFCyo1VR+CHe/Cx/+Cj9+xQ0iDPf+7YDyMuhUGXGhn29HfgQ4j9QId4NxbYP2rsOUNOPuqxBamVDzUVdqzTz5+B7b/y3YpYmwLvP8FdtjYgRPt2Ccer9PVKoe4NtDT/B5qmp7l0ujMyyCrB6x+TgNduVND0I6Bsv1t2L7InpESqrcD0fUrgksetAGeN0bn01XHRBXoIjIZ+DXgBZ42xjzcwnZjgWXATcaYF2NWZTPSfV7qgiFCIYPH0+RsFq8fRnzODgVQdVAvOVbJzxg4uB22vWUD/OPFUHsEEDt87Pj/gIEX2+6UQKbT1aokdcpAFxEv8AQwCSgGlovIPGPM+ma2+ymwIB6FNpXut/9W1gZDZASa+Rfz3Jth2ZOw9iU9J10lp5ojsO1tG+Lb3j4+BniXAhg2FQZdakM8K8fZOpVrRNNCLwK2GmO2A4jIXGAqsL7Jdl8BXgLGxrTCFqT77TgRNfUNzQd6n5F29u7Vz2ugq+RgjD14uWWhPb6zaymEgvZA5sCJMOE/7WiEOoGDaqdoAj0P2B3xvBg4P3IDEckDrgM+RSuBLiLTgekABQUFba31BI0t9JpgCwdGwbbSF34byjZDj7NOa39KtUtdlT2VcPMCG+KNrfBew+GCr8DgK+254HopvYqBaH6KmmsqmCbPHwEeMMY0SCstC2PMbGA2QGFhYdP3aJPjLfQWDoyCvXz5jYdsK/3y753O7pSK3sGPbXhvWWD7whtqwZ8Fgy6Bi74Bg6+ALnlOV6lSUDSBXgxEDuaQD+xtsk0hMDcc5rnAVSISNMa8Eosim5PuC7fQWzp1EaBTTztW+qrn7MhwvrR4laM6smCd7T7ZstDeGi/q6X4GFN4FZ10B/Sfoz5+Ku2gCfTkwWEQGAnuAacAtkRsYYwY2PhaRZ4C/xzPMIaLLpbVABzs34Z+us4N2Fd4Vz5JUR1K+D7a+YbtSti+CugrwBuzFPIV32VZ4zhlOV6k6mFMGujEmKCL3Yc9e8QJzjDHrRGRGeP2sONfYrLRoulzAnimQVwiL/x+Muk3P2VXtEwrZ4WU3v25b4Z+sscs758GIz9q+8IETIa2Ts3WqDi2qIzHGmPnA/CbLmg1yY8wXTr+sU4vqoCjYswUu/W949npY/Eu49MEEVKdSQrDWXpm58e+wcb6d3Fi8dmyUy75nW+G9hukZKSppuPbQemMfeu2pulzAXjk64kZ45+d2iN2zroxzdcq1aivswcwN/2cPbNZV2Bl6zrwczv60/VnSC9VUknJvoEfb5dLo6l/ag1Vzb7Et9nOmQkZX2woL1tj7Tj0hM0dbXB1N7VHY9DqsfwW2vml/HrJ62Bmwzv40DLpYD2gqV3BxoEd5UPTYCzrDHa/Cq/fCP39ob81J6wzdBtiJps+60vaN6nCjqafmSESI/9OeWtipN4y+A4Zea2fq0UGulMt0nEAH2yKf9mf4ZC2UrLXTcPnSwJduL+w4WgKHPrZjamz8hz0zplNvuPz7cO40bbm7XfVh2PSaDfFtb0FDHWT3tWelDLsW8ot0pnrlai4O9HCXS0sjLram93B7a01DED5eBIsehldm2FHvrv6VnsXgNnVVsPk1+Ogle5phQx106QdF021LPG+MhrhKGa4N9LRoLiw6HV6fPRA26FJ7dszbP4bS9fCFf0B6l/jsU8VGsM62wNe+aM9Oqa+E7D4w9ku2XzxvtP63pVKSawPd6xECXg/V8Qr0Rh4vXPwtO/PL3Ftg7q1w64var55sjLEz1696Fta9bGf0yegGIz8Hwz9rJ4HQPnGV4lwb6ACZaV6qauMc6I3OuhKufQr+9iV4eTp89vcaEMmgogzW/AU+fBbKNoAvA86+2o7jM+hSvZBMdSiuDvSsgI/KumDidjjyRqgogYXfgddnwpSf6b/uTmgI2v7wD5+1V26GgnbEws/8GoZdp11iqsNydaB3SvNRWZvAQAc75OnRT2Dp4/asiJGfS+z+O7KyzbZLZfVc+4c1qweMu8cO6dDzbKerU8pxrg70zDQvlYnqcok06Yewaxm8/oCdkEBnlImfmnLbJ/7hs1D8vr30/qzJcN5tMHiSzmivVARXB3qnNB8ViW6hg+07v+Yx+M1FsOBBuH524mtIZcbAziU2xNe/AvVVkDsErvgfGHmTvaJXKXUSVwd6ZsBLSXmNMzvvNRQu/Aa88zM7Tszgy52pI5VUH7Jj16+YAwe2QiDbHrc473Z7vrger1CqVa4O9Kw0nzNdLo0m3m9bkH//GvzHMr3oqL0+WQvvzYKPXoRgNfQbBxO/CedcozPcK9UG7g70RJ/l0pQvzXa9zLkS3voRTPmpc7W4TajBTg6x7Ek756Y/E869CcbebcfRUUq1mbsD3YmzXJoqGAeFX4T3Z8OYL0DPc5ytJ9nVlNsxct6bBYd2QOd8e5B59B32QiClVLu5OtA7pXmpbzDUBUMEfA6Ox/Gp79jugoXfhdtedK6OZHZwO7w32x7orDtqu1Uu/z6c/Rmd8V6pGHH1b1JmwJZfWRsk4OQVgZnd4eJv2guOti+ys7ur8Nkq78LSJ2HTfHt20LDr7TyveWOcrk6plOPqQO+UFg70uiDdshy+xHvsl2DZLDvO+sCLO/YZGaGQvYLz37+C4uV20pCJ99uuqc59nK5OqZQVVT+FiEwWkU0islVEZjazfqqIrBGRVSKyQkQujH2pJ8tMs2OpOHqmSyN/Olwy004kvPHvTlfjjIZ6exXnUxfA3Jvt1ZxX/QK+vs52S2mYKxVXp2yhi4gXeAKYBBQDy0VknjFmfcRm/wTmGWOMiIwEXgDifi12VkQLPSmcezO8+2t4639gyFUdZ/Cu+mrbN77kUTi8C3qcA9fNhuHX65WcSiVQNF0uRcBWY8x2ABGZC0wFjgW6MaYiYvsswMSyyJZkRfShJwWvDz71bfjrF2DNCzDqZqcriq/qw7D8aVj2FFTtt2PbTPmZnbZPJ41QKuGiCfQ8YHfE82Lg/KYbich1wE+AnsDVzb2RiEwHpgMUFBS0tdaTdM6w5ZdXJ0mgg518us+5sOjHtoWaipMLVx20rfH3n7ZnrJx5OUz4Ggy4sGMfO1DKYdE0o5r7DT2pBW6MedkYczZwLfCj5t7IGDPbGFNojCns0aNHmwptTtcMeyD0cHXdab9XzHg8cNlDtuth5R+dria2qg/Z7qRHRsC/H7GDY315Mdz2Egy8SMNcKYdF00IvBvpFPM8H9ra0sTHmHRE5Q0RyjTH7T7fA1nTNtP2zR6rr47mbtjvjMug/Ad75ue1Xd/uQALUVsPQJO2Rwbbkdc/ziB/QiKqWSTDQt9OXAYBEZKCIBYBowL3IDETlTxDbPRGQ0EAAOxLrYptL9XtJ8Ho5UJVmgi8DlP7BneSz+pdPVtF9D0PaRP3qe7UIaOBFmvAufe0bDXKkkdMoWujEmKCL3AQsALzDHGLNORGaE188CbgDuEJF6oBq4yRiTkAOjXTP9HE62QAfoNxZGTrMt2zGfh24DnK4oesbA1jdhwbdh/yYouACmPWe/JqVU0orqwiJjzHxgfpNlsyIe/xRwZGSqLhn+5OpDj3TZQ7BhHrzxPbjxD05XE52SdfaK121vQfdBcNOf7Ryd2j+uVNJz9ZWiYA+MJmULHaBLnj37Y9GP7YQN/S9wuqKWVe63I0au/COkZcOVP7EjH+oky0q5hutPFu6S6U++g6KRLvgKdM6DBf9tuzKSTUMQ3vsNPDbaXhxUNB3+cxWM/w8Nc6VcxvWB3jUjSfvQGwUy7WXvez+0k2Ekkx3/ht9MhNe+BX3Pg3uW2DHdM7s7XZlSqh3cH+iZtg89Qcdg22fkTdBzqB24qyEJ/vgc2gF/vROeuRpqj8KNf4LbX4EeQ5yuTCl1Glwf6Lmd0qipDzkzWXS0PF479vfB7bZ7wylVB+2ZK4+PtcPZXvwA3PseDL1GD3oqlQJcf1C0Z2d7aX3Z0Vqy05N4IKjBV9gxTt7+MQy7FrrkJ27f9TV2RqXFv7AzBp13K1zy3/agrVIqZbi+hd4zOx2A0qO1DldyCiJw1c/BhOC1BxKzz1AIVv8FHi+EN75rB8+6512Y+oSGuVIpKAUC3bbQkz7QAbr1h0sesOOlb3otvvvavghmXwwvT7cHOe941U6P12tYfPerlHKM+7tcGlvo5TUOVxKl8ffZVvP8b0G/82N/RknJOnjjIXulZ5cCuP5pGH6DDmerVAfg+t/yzhk+Aj4PZW5ooYOd8OGaR+04L7+7Ag7tjM37HtkDr9wLT02w075d8T9w33IY+TkNc6U6CNf/posIPbPTKHFLCx2gXxHc/jJUlsLvJsHeVe1/r5oj9nTIx8bARy/ABffZC4Mu+IqdFk8p1WG4PtAB8rtlsPtQtdNltM2ACXDXQvAG4PdTYN0rbXt91UFY8rgdCXHxL+Gcz8B9K2zLXC8MUqpDcn0fOkD/7ln8c2Op02W0Xc+z4e43Ye6t8NfPw8d32QG9Mro1v32wDrYshNXPw+YFEKq3Q9pO+qG90lMp1aGlRqDnZrK/opaK2iCd0lz2JWX3hjtfg7d+CEseg49ehMK74KwrIXeInVCibKMN8PWvQvVByOoJ538Zzp0GvUc4/RUopZKEy9KveQNysgDYeaCSYX27OFxNO/gCtqtk5DT418N2vs53Hzlxm0AnO+XbubfAGZ+yE1IrpVSElEiFgu6ZAOw6UOXOQG/Uezjc9Kydu/PjxVC+B9I626tKC8al5oTTSqmYSYlAH5hrW+ibSyqYkgo9EBnd7PgqSinVBilxlktWmo9BuVms23vE6VKUUsoxKRHoAMPzurBub7nTZSillGOiCnQRmSwim0Rkq4jMbGb9rSKyJnxbIiLnxr7U1g3P68yew9UcrEzS+UWVUirOThnoIuIFngCmAEOBm0VkaJPNPgYuNsaMBH4EzI51oacyqp89d3v5joOJ3rVSSiWFaFroRcBWY8x2Y0wdMBeYGrmBMWaJMeZQ+OkyIIGDfVuj+nUlM+Dl31v2J3rXSimVFKIJ9Dxgd8Tz4vCylnwRaHZsWBGZLiIrRGRFWVlZ9FVGIeDzMG5QDv/eqoGulOqYogn05uYma3YCTxG5FBvozc7gYIyZbYwpNMYU9ujRI/oqozRxcC4f769kS8nRmL+3Ukolu2gCvRjoF/E8H9jbdCMRGQk8DUw1xhyITXltc9WIPngE5q0+qTyllEp50QT6cmCwiAwUkQAwDZgXuYGIFAB/A243xmyOfZnR6dk5nfFn5DBv9V6MafafCKWUSlmnDHRjTBC4D1gAbABeMMasE5EZIjIjvNlDQA7wpIisEpEVcav4FG4Ync/OA1Us1oOjSqkORpxqyRYWFpoVK2Kf+7XBBiY8/DbD8zrzzJ1FMX9/pZRykoh8YIwpbG5dylwp2ijN5+WO8f1ZtKmMjZ/olaNKqY4j5QId4I7x/clO9/GLBY515yulVMKlZKB3zQzw5YmDeHNDCR/sPHTqFyilVApIyUAHuOvCgfTMTuOhV9cSbAg5XY5SSsVdygZ6ZsDH968Zxrq95fz+3R1Ol6OUUnGXsoEOMGV4by4/pxe/WLiJDfv0AKlSKrWldKCLCD+5fgRdMvzc8+wHHKmud7okpZSKm5QOdIAe2Wk8ceto9hyu5q5nllNZG3S6JKWUiouUD3SAsQO68+i081i1+zB3zHmfsqO1TpeklFIx1yECHWDKiD48dvN5rNt7hE8/tpjX1+7T8V6UUimlwwQ62NEYX7rnArplBpjx7EpueGoJ/1izj3o9rVEplQJSbiyXaAQbQjy/fDdPL97OzgNV5GQFuHpkH6aOymN0QVdEmhsCXimlnNfaWC4dMtAbNYQMizaV8rcP9/Dm+hJqgyEKumdy3Xl53DA6n4KcTEfrU0qppjTQo3C0pp4F60p4+cNilmw7gDFQNKA7N4zJY+qoPNL9XqdLVEopDfS22nu4mpc/3MNLK4vZXlZJTlaAz18wgDsnDCA73e90eUqpDkwDvZ2MMbz38UFmv7OdtzaWkpMV4GuTzuLWogI8Hu1nV0olXocaDz2WRIRxg3KY84WxzLtvAmf27MR3X1nLtNnL2LG/0unylFLqBBroURqZ35W508fxi8+dy4ZPypny68W8/GGx02UppdQxGuhtICJ8dkw+C78+kZH5Xfj6X1bzvVfXUhfU89iVUs6LKtBFZLKIbBKRrSIys5n1Z4vIUhGpFZH7Y19mcunTJYNn7z6fuy8cyB+W7uSuZ5ZToWPEKKUcdspAFxEv8AQwBRgK3CwiQ5tsdhD4T+AXMa8wSfm9Hr7z6aH87LMjWbr9ANNmL9UxYpRSjoqmhV4EbDXGbDfG1AFzgamRGxhjSo0xy4EONz7tjYX9ePqOQraVVnLjb5ZSUl7jdElKqQ4qmkDPA3ZHPC8OL1Nhl57dk2fvLqK0vIabZy+jVENdKeWAaAK9uROu23XyuohMF5EVIrKirKysPW+RtMb0784zdxXxSXkNN/92GaVHNdSVUokVTaAXA/0inucDe9uzM2PMbGNMoTGmsEePHu15i6Q2dkB3nrmziH1Harjlt+9xoEL71JVSiRNNoC8HBovIQBEJANOAefEty72KBnZnzhfGUnyoitt+9z5HqjrcYQWllENOGejGmCBwH7AA2AC8YIxZJyIzRGQGgIj0FpFi4BvAd0SkWEQ6x7PwZDZuUA6zby9kW2kFd/z+fY7WaKgrpeJPx3KJo4XrPuGeP69kTEE3/nBXERkBHbFRKXV6dCwXh1wxrDeP3DSKFTsPMv1PK6gNNjhdklIqhWmgx9lnzu3LT28YyeIt+7n3zx/qdHdKqbjRQE+AzxX240dTh/HmhhK+/pdVNIR0cmqlVOz5nC6go7h9/ACq6xv48fyNpPu9/OyGkTqmulIqpjTQE2j6xDOoqmvgkTe34PMI/3vdCLwa6kqpGNFAT7CvXjaYhpDhsbe2UlEb5Fc3jiLg054vpdTp00BPMBHhv64YQqc0Hz95bSOVtUGevHWMntKolDpt2jR0yJcvPoMfXzeCRZvL+LxefKSUigENdAfdcn4Bj9w0ipU7D3HDU0t0nlKl1GnRQHfY1FF5PHNnEaVHa7nm8X/z5voSp0tSSrmUBnoSuHBwLvPuvZD8bpnc/ccVzHxpjU5pp5RqMw30JFGQk8nL917APZecwQsrdjP5kXdYsnW/02UppVxEAz2JpPm8PDD5bP46Yzxej3DL0+9xz7MfsPtgldOlKaVcQAM9CY3p350FX5vIf006i0WbyrjsV//iR39fr1PbKaVapcPnJrl9R6r5xYLNvLJqD16PcFNhP24b158hvbOdLk0p5YDWhs/VQHeJnQcqefLtbbz84R7qGkKMLujKzUUFTB7em+x0v9PlKaUSRAM9hRysrONvK4t57v1dbC+rxO8VLjgjlyuH9ebyoT3pmZ3udIlKqTjSQE9BxhhW7jrE62s/YcG6EnaFD5wO6ZXN+YO6M25QDmMHdKdHdprDlSqlYkkDPcUZY9hUcpR/bihl2fYDrNhxiOp6OztSz+w0zunTOXzLZkjvbPp3z9KxY5RyqdYCXQfnSgEiwtm9O3N2787ce+mZ1DeE+GjPEVbuPMT6feVs2HeUJdu2U99w/I93z+w0+udkUtA9i7yu6fTsnE6vzun06pxGr87p5GQF8Hn1JCil3CSqQBeRycCvAS/wtDHm4SbrJbz+KqAK+IIxZmWMa1VR8ns9jC7oxuiCbseW1QVDbCurYEtpBbsOVLLzQBU7D1bx7tb9lB6toekkSiLQOd1P10w/XTMDdM0IP87w0yUzQKc0L5kBH1mN9wEfmWleex/wkpVm7wNej07koVSCnDLQRcQLPAFMAoqB5SIyzxizPmKzKcDg8O184KnwvUoSAZ/nWNdLU8GGEAcq6ygpr6GkvJbSozWUltdyuKqOw9X1HK6q53BVHTsOVHK4qp7ymnra0lPn9woBr4eAz97SfF77+IRl9nma//hyn9eDzyN4PRK+9+D1gNfTdHn4/qTtBV/4NSKCRwSPgEcECd83LpPGdZ7I51FsH14mEa9tfC403tvtofGxXUf471zkNo1/+iJfTzPLjm8nx99T9A9nRxdNC70I2GqM2Q4gInOBqUBkoE8F/mhsh/wyEekqIn2MMftiXrGKOZ/XE+5uie4MmYaQobq+garaIJV1DVTWBqmqa6CyLkhVbeO9XVcXDFHXEKIuGKI2GH5+wjJ7X1EbpLb++PK6YIhgyNAQarw3x+51TtZTi+oPCSf/4TjhD0vTZRF/SI7v58QlcsK6k6pqcV1rr5Mmez3hj9wp6mnpdSe/T/v3IS0+afp1HX82bWw/7r5oUIu1tlc0gZ4H7I54XszJre/mtskDTgh0EZkOTAcoKChoa60qSXg9Qqc0H53SnDkEY0w42E1E0DeYiOAPnfAHINhgMBiMgZAxhML3pvFxyN6biHV2fQvbm8jtDaEQLW5v4Nh/M5HPTcTXwrFlkY9PXnbsPRofR2wTuYym+w2vb7qMY8ui3O9J34cmzyO2OHldy6+jtdfFaB8nVW+afRh+rWllXWv7NC2ua/pGuZ3ic/ZZNL+Rzf3Ja/p1RrMNxpjZwGywZ7lEsW+lTiIi+LyiR/SVaiKa0xiKgX4Rz/OBve3YRimlVBxFE+jLgcEiMlBEAsA0YF6TbeYBd4g1Djii/edKKZVYp/yv1RgTFJH7gAXY0xbnGGPWiciM8PpZwHzsKYtbsact3hm/kpVSSjUnqm5IY8x8bGhHLpsV8dgA98a2NKWUUm2hlwIqpVSK0EBXSqkUoYGulFIpQgNdKaVShGPD54pIGbCznS/PBfbHsJxYSda6IHlr07raRutqm1Ssq78xpkdzKxwL9NMhIitaGg/YSclaFyRvbVpX22hdbdPR6tIuF6WUShEa6EoplSLcGuiznS6gBclaFyRvbVpX22hdbdOh6nJlH7pSSqmTubWFrpRSqgkNdKWUShGuC3QRmSwim0Rkq4jMdGD/O0TkIxFZJSIrwsu6i8gbIrIlfN8tYvsHw7VuEpErY1jHHBEpFZG1EcvaXIeIjAl/PVtF5FE5zYkpW6jr+yKyJ/yZrRKRqxyoq5+IvC0iG0RknYh8Nbzc0c+slboc/cxEJF1E3heR1eG6fhBe7vTn1VJdjv+Mhd/TKyIfisjfw88T+3mZxqmyXHDDDt+7DRgEBIDVwNAE17ADyG2y7GfAzPDjmcBPw4+HhmtMAwaGa/fGqI6JwGhg7enUAbwPjMfOOvUaMCUOdX0fuL+ZbRNZVx9gdPhxNrA5vH9HP7NW6nL0Mwu/R6fwYz/wHjAuCT6vlupy/Gcs/J7fAJ4D/u7E76TbWujHJqw2xtQBjRNWO20q8Ifw4z8A10Ysn2uMqTXGfIwdL74oFjs0xrwDHDydOkSkD9DZGLPU2J+kP0a8JpZ1tSSRde0zxqwMPz4KbMDOe+voZ9ZKXS1JVF3GGFMRfuoP3wzOf14t1dWShP2MiUg+cDXwdJP9J+zzclugtzQZdSIZYKGIfCB20muAXiY8Q1P4vmd4eaLrbWsdeeHHiajvPhFZI7ZLpvHfTkfqEpEBwHnY1l3SfGZN6gKHP7Nw98EqoBR4wxiTFJ9XC3WB8z9jjwDfAkIRyxL6ebkt0KOajDrOJhhjRgNTgHtFZGIr2yZDvdByHYmq7yngDGAUsA/4pVN1iUgn4CXga8aY8tY2TWRtzdTl+GdmjGkwxozCzhFcJCLDW9nc6boc/bxE5NNAqTHmg2hfEo+63Bbojk9GbYzZG74vBV7GdqGUhP9VInxfGt480fW2tY7i8OO41meMKQn/EoaA33K82ymhdYmIHxuafzbG/C282PHPrLm6kuUzC9dyGFgETCYJPq/m6kqCz2sCcI2I7MB2BX9KRJ4l0Z/X6R4ESOQNO2XeduxBhMaDosMSuP8sIDvi8RLsD/nPOfHAx8/Cj4dx4oGP7cTooGj4/Qdw4sHHNteBnQR8HMcPwFwVh7r6RDz+OrbvMKF1hd/nj8AjTZY7+pm1UpejnxnQA+gafpwBLAY+nQSfV0t1Of4zFrH/Szh+UDShn1dMgiWRN+xk1JuxR4W/neB9Dwp/E1YD6xr3D+QA/wS2hO+7R7zm2+FaNxGDo+gR7/s89l/Leuxf9S+2pw6gEFgbXvc44auHY1zXn4CPgDXAvCa/fImq60Lsv65rgFXh21VOf2at1OXoZwaMBD4M738t8FB7f9YTVJfjP2MR73sJxwM9oZ+XXvqvlFIpwm196EoppVqgga6UUilCA10ppVKEBrpSSqUIDXSllEoRGuhKKZUiNNCVUipF/H/o9YP+ynRJVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simply Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "1/1 [==============================] - 1s 505ms/step - loss: 0.7104 - accuracy: 0.3333 - val_loss: 0.6971 - val_accuracy: 0.3286\n",
      "Epoch 2/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6936 - accuracy: 0.3667 - val_loss: 0.6864 - val_accuracy: 0.6143\n",
      "Epoch 3/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6773 - accuracy: 0.8333 - val_loss: 0.6761 - val_accuracy: 0.7000\n",
      "Epoch 4/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6614 - accuracy: 0.8667 - val_loss: 0.6660 - val_accuracy: 0.7143\n",
      "Epoch 5/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6461 - accuracy: 0.8667 - val_loss: 0.6563 - val_accuracy: 0.7143\n",
      "Epoch 6/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6311 - accuracy: 0.8667 - val_loss: 0.6470 - val_accuracy: 0.7143\n",
      "Epoch 7/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6166 - accuracy: 0.8667 - val_loss: 0.6379 - val_accuracy: 0.7143\n",
      "Epoch 8/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6025 - accuracy: 0.8667 - val_loss: 0.6292 - val_accuracy: 0.7143\n",
      "Epoch 9/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5888 - accuracy: 0.8667 - val_loss: 0.6207 - val_accuracy: 0.7143\n",
      "Epoch 10/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5755 - accuracy: 0.8667 - val_loss: 0.6126 - val_accuracy: 0.7143\n",
      "Epoch 11/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5625 - accuracy: 0.8667 - val_loss: 0.6047 - val_accuracy: 0.7143\n",
      "Epoch 12/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5500 - accuracy: 0.8667 - val_loss: 0.5972 - val_accuracy: 0.7143\n",
      "Epoch 13/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5378 - accuracy: 0.8667 - val_loss: 0.5899 - val_accuracy: 0.7143\n",
      "Epoch 14/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5259 - accuracy: 0.8667 - val_loss: 0.5829 - val_accuracy: 0.7143\n",
      "Epoch 15/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5144 - accuracy: 0.8667 - val_loss: 0.5762 - val_accuracy: 0.7143\n",
      "Epoch 16/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5032 - accuracy: 0.8667 - val_loss: 0.5697 - val_accuracy: 0.7143\n",
      "Epoch 17/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4923 - accuracy: 0.8667 - val_loss: 0.5635 - val_accuracy: 0.7143\n",
      "Epoch 18/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4817 - accuracy: 0.8667 - val_loss: 0.5575 - val_accuracy: 0.7143\n",
      "Epoch 19/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4714 - accuracy: 0.8667 - val_loss: 0.5517 - val_accuracy: 0.7143\n",
      "Epoch 20/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4614 - accuracy: 0.8667 - val_loss: 0.5462 - val_accuracy: 0.7143\n",
      "Epoch 21/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4517 - accuracy: 0.8667 - val_loss: 0.5409 - val_accuracy: 0.7143\n",
      "Epoch 22/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4422 - accuracy: 0.8667 - val_loss: 0.5358 - val_accuracy: 0.7143\n",
      "Epoch 23/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4330 - accuracy: 0.8667 - val_loss: 0.5309 - val_accuracy: 0.7143\n",
      "Epoch 24/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4241 - accuracy: 0.9000 - val_loss: 0.5262 - val_accuracy: 0.7143\n",
      "Epoch 25/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4154 - accuracy: 0.9000 - val_loss: 0.5217 - val_accuracy: 0.7143\n",
      "Epoch 26/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4070 - accuracy: 0.9000 - val_loss: 0.5174 - val_accuracy: 0.7143\n",
      "Epoch 27/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3988 - accuracy: 0.9000 - val_loss: 0.5133 - val_accuracy: 0.7286\n",
      "Epoch 28/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3909 - accuracy: 0.9000 - val_loss: 0.5094 - val_accuracy: 0.7286\n",
      "Epoch 29/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3832 - accuracy: 0.9000 - val_loss: 0.5057 - val_accuracy: 0.7286\n",
      "Epoch 30/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3758 - accuracy: 0.9000 - val_loss: 0.5022 - val_accuracy: 0.7286\n",
      "Epoch 31/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3686 - accuracy: 0.9000 - val_loss: 0.4989 - val_accuracy: 0.7286\n",
      "Epoch 32/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3616 - accuracy: 0.9000 - val_loss: 0.4957 - val_accuracy: 0.7286\n",
      "Epoch 33/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3549 - accuracy: 0.9000 - val_loss: 0.4927 - val_accuracy: 0.7286\n",
      "Epoch 34/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3484 - accuracy: 0.9000 - val_loss: 0.4899 - val_accuracy: 0.7286\n",
      "Epoch 35/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3421 - accuracy: 0.9000 - val_loss: 0.4872 - val_accuracy: 0.7286\n",
      "Epoch 36/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3360 - accuracy: 0.9000 - val_loss: 0.4847 - val_accuracy: 0.7286\n",
      "Epoch 37/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3301 - accuracy: 0.9000 - val_loss: 0.4823 - val_accuracy: 0.7286\n",
      "Epoch 38/4000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3245 - accuracy: 0.9000 - val_loss: 0.4801 - val_accuracy: 0.7286\n",
      "Epoch 39/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3190 - accuracy: 0.9000 - val_loss: 0.4780 - val_accuracy: 0.7286\n",
      "Epoch 40/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3138 - accuracy: 0.9000 - val_loss: 0.4761 - val_accuracy: 0.7286\n",
      "Epoch 41/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3087 - accuracy: 0.9000 - val_loss: 0.4742 - val_accuracy: 0.7286\n",
      "Epoch 42/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3039 - accuracy: 0.8667 - val_loss: 0.4725 - val_accuracy: 0.7286\n",
      "Epoch 43/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2992 - accuracy: 0.8667 - val_loss: 0.4709 - val_accuracy: 0.7286\n",
      "Epoch 44/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2947 - accuracy: 0.9000 - val_loss: 0.4694 - val_accuracy: 0.7286\n",
      "Epoch 45/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2903 - accuracy: 0.9000 - val_loss: 0.4680 - val_accuracy: 0.7286\n",
      "Epoch 46/4000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2862 - accuracy: 0.9000 - val_loss: 0.4666 - val_accuracy: 0.7286\n",
      "Epoch 47/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2822 - accuracy: 0.9000 - val_loss: 0.4654 - val_accuracy: 0.7286\n",
      "Epoch 48/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2783 - accuracy: 0.9000 - val_loss: 0.4642 - val_accuracy: 0.7286\n",
      "Epoch 49/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2746 - accuracy: 0.9000 - val_loss: 0.4631 - val_accuracy: 0.7286\n",
      "Epoch 50/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2711 - accuracy: 0.9000 - val_loss: 0.4620 - val_accuracy: 0.7286\n",
      "Epoch 51/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2677 - accuracy: 0.9000 - val_loss: 0.4610 - val_accuracy: 0.7286\n",
      "Epoch 52/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2644 - accuracy: 0.9000 - val_loss: 0.4601 - val_accuracy: 0.7286\n",
      "Epoch 53/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2612 - accuracy: 0.9000 - val_loss: 0.4592 - val_accuracy: 0.7286\n",
      "Epoch 54/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2582 - accuracy: 0.9000 - val_loss: 0.4583 - val_accuracy: 0.7286\n",
      "Epoch 55/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2553 - accuracy: 0.9000 - val_loss: 0.4575 - val_accuracy: 0.7286\n",
      "Epoch 56/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2525 - accuracy: 0.9000 - val_loss: 0.4567 - val_accuracy: 0.7286\n",
      "Epoch 57/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2498 - accuracy: 0.9000 - val_loss: 0.4559 - val_accuracy: 0.7286\n",
      "Epoch 58/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2472 - accuracy: 0.9000 - val_loss: 0.4552 - val_accuracy: 0.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2447 - accuracy: 0.9000 - val_loss: 0.4545 - val_accuracy: 0.7286\n",
      "Epoch 60/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2423 - accuracy: 0.9000 - val_loss: 0.4538 - val_accuracy: 0.7286\n",
      "Epoch 61/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2400 - accuracy: 0.9000 - val_loss: 0.4531 - val_accuracy: 0.7286\n",
      "Epoch 62/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2378 - accuracy: 0.9000 - val_loss: 0.4525 - val_accuracy: 0.7429\n",
      "Epoch 63/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2357 - accuracy: 0.9000 - val_loss: 0.4518 - val_accuracy: 0.7429\n",
      "Epoch 64/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2336 - accuracy: 0.9000 - val_loss: 0.4512 - val_accuracy: 0.7429\n",
      "Epoch 65/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2317 - accuracy: 0.8667 - val_loss: 0.4506 - val_accuracy: 0.7429\n",
      "Epoch 66/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2298 - accuracy: 0.8667 - val_loss: 0.4500 - val_accuracy: 0.7429\n",
      "Epoch 67/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2280 - accuracy: 0.8667 - val_loss: 0.4494 - val_accuracy: 0.7429\n",
      "Epoch 68/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2262 - accuracy: 0.8667 - val_loss: 0.4488 - val_accuracy: 0.7429\n",
      "Epoch 69/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2245 - accuracy: 0.8667 - val_loss: 0.4482 - val_accuracy: 0.7429\n",
      "Epoch 70/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2229 - accuracy: 0.8667 - val_loss: 0.4477 - val_accuracy: 0.7429\n",
      "Epoch 71/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2213 - accuracy: 0.8667 - val_loss: 0.4471 - val_accuracy: 0.7429\n",
      "Epoch 72/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2198 - accuracy: 0.8667 - val_loss: 0.4466 - val_accuracy: 0.7429\n",
      "Epoch 73/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2183 - accuracy: 0.8667 - val_loss: 0.4461 - val_accuracy: 0.7429\n",
      "Epoch 74/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2169 - accuracy: 0.8667 - val_loss: 0.4455 - val_accuracy: 0.7429\n",
      "Epoch 75/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2155 - accuracy: 0.8667 - val_loss: 0.4450 - val_accuracy: 0.7429\n",
      "Epoch 76/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2142 - accuracy: 0.8667 - val_loss: 0.4445 - val_accuracy: 0.7429\n",
      "Epoch 77/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2129 - accuracy: 0.8667 - val_loss: 0.4440 - val_accuracy: 0.7429\n",
      "Epoch 78/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2117 - accuracy: 0.8667 - val_loss: 0.4435 - val_accuracy: 0.7429\n",
      "Epoch 79/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2105 - accuracy: 0.8667 - val_loss: 0.4430 - val_accuracy: 0.7429\n",
      "Epoch 80/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2093 - accuracy: 0.8667 - val_loss: 0.4425 - val_accuracy: 0.7429\n",
      "Epoch 81/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2082 - accuracy: 0.8667 - val_loss: 0.4420 - val_accuracy: 0.7429\n",
      "Epoch 82/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2071 - accuracy: 0.8667 - val_loss: 0.4415 - val_accuracy: 0.7429\n",
      "Epoch 83/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2060 - accuracy: 0.8667 - val_loss: 0.4410 - val_accuracy: 0.7429\n",
      "Epoch 84/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2049 - accuracy: 0.9000 - val_loss: 0.4405 - val_accuracy: 0.7429\n",
      "Epoch 85/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2039 - accuracy: 0.9000 - val_loss: 0.4400 - val_accuracy: 0.7429\n",
      "Epoch 86/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2029 - accuracy: 0.9000 - val_loss: 0.4395 - val_accuracy: 0.7429\n",
      "Epoch 87/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2020 - accuracy: 0.9000 - val_loss: 0.4390 - val_accuracy: 0.7429\n",
      "Epoch 88/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2010 - accuracy: 0.9000 - val_loss: 0.4385 - val_accuracy: 0.7429\n",
      "Epoch 89/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2001 - accuracy: 0.9000 - val_loss: 0.4380 - val_accuracy: 0.7429\n",
      "Epoch 90/4000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1992 - accuracy: 0.9000 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
      "Epoch 91/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1983 - accuracy: 0.9000 - val_loss: 0.4370 - val_accuracy: 0.7429\n",
      "Epoch 92/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1974 - accuracy: 0.9000 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
      "Epoch 93/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1966 - accuracy: 0.9000 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
      "Epoch 94/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1957 - accuracy: 0.9000 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
      "Epoch 95/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1949 - accuracy: 0.9000 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
      "Epoch 96/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1941 - accuracy: 0.9000 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
      "Epoch 97/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1933 - accuracy: 0.9000 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
      "Epoch 98/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1926 - accuracy: 0.9000 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
      "Epoch 99/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1918 - accuracy: 0.9000 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
      "Epoch 100/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1911 - accuracy: 0.9000 - val_loss: 0.4314 - val_accuracy: 0.7429\n",
      "Epoch 101/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1903 - accuracy: 0.9000 - val_loss: 0.4308 - val_accuracy: 0.7429\n",
      "Epoch 102/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1896 - accuracy: 0.9000 - val_loss: 0.4301 - val_accuracy: 0.7429\n",
      "Epoch 103/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1889 - accuracy: 0.9000 - val_loss: 0.4294 - val_accuracy: 0.7429\n",
      "Epoch 104/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1882 - accuracy: 0.9000 - val_loss: 0.4286 - val_accuracy: 0.7429\n",
      "Epoch 105/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1875 - accuracy: 0.9000 - val_loss: 0.4279 - val_accuracy: 0.7429\n",
      "Epoch 106/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1868 - accuracy: 0.9000 - val_loss: 0.4272 - val_accuracy: 0.7429\n",
      "Epoch 107/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1861 - accuracy: 0.9000 - val_loss: 0.4264 - val_accuracy: 0.7429\n",
      "Epoch 108/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1855 - accuracy: 0.9000 - val_loss: 0.4257 - val_accuracy: 0.7429\n",
      "Epoch 109/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1848 - accuracy: 0.9000 - val_loss: 0.4249 - val_accuracy: 0.7429\n",
      "Epoch 110/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1842 - accuracy: 0.9000 - val_loss: 0.4242 - val_accuracy: 0.7429\n",
      "Epoch 111/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1835 - accuracy: 0.9000 - val_loss: 0.4234 - val_accuracy: 0.7429\n",
      "Epoch 112/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1829 - accuracy: 0.9000 - val_loss: 0.4226 - val_accuracy: 0.7429\n",
      "Epoch 113/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1823 - accuracy: 0.9000 - val_loss: 0.4219 - val_accuracy: 0.7429\n",
      "Epoch 114/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1817 - accuracy: 0.9000 - val_loss: 0.4211 - val_accuracy: 0.7571\n",
      "Epoch 115/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1810 - accuracy: 0.9000 - val_loss: 0.4204 - val_accuracy: 0.7571\n",
      "Epoch 116/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1805 - accuracy: 0.9000 - val_loss: 0.4196 - val_accuracy: 0.7571\n",
      "Epoch 117/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1799 - accuracy: 0.9000 - val_loss: 0.4189 - val_accuracy: 0.7571\n",
      "Epoch 118/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1793 - accuracy: 0.9000 - val_loss: 0.4181 - val_accuracy: 0.7571\n",
      "Epoch 119/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1787 - accuracy: 0.9000 - val_loss: 0.4174 - val_accuracy: 0.7571\n",
      "Epoch 120/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1781 - accuracy: 0.9000 - val_loss: 0.4166 - val_accuracy: 0.7714\n",
      "Epoch 121/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1775 - accuracy: 0.9000 - val_loss: 0.4159 - val_accuracy: 0.7714\n",
      "Epoch 122/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1770 - accuracy: 0.9000 - val_loss: 0.4151 - val_accuracy: 0.7714\n",
      "Epoch 123/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1764 - accuracy: 0.9000 - val_loss: 0.4144 - val_accuracy: 0.7714\n",
      "Epoch 124/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1759 - accuracy: 0.9000 - val_loss: 0.4136 - val_accuracy: 0.7714\n",
      "Epoch 125/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1753 - accuracy: 0.9333 - val_loss: 0.4129 - val_accuracy: 0.7714\n",
      "Epoch 126/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1748 - accuracy: 0.9333 - val_loss: 0.4121 - val_accuracy: 0.7857\n",
      "Epoch 127/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1743 - accuracy: 0.9333 - val_loss: 0.4114 - val_accuracy: 0.7857\n",
      "Epoch 128/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 0.4106 - val_accuracy: 0.7857\n",
      "Epoch 129/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1732 - accuracy: 0.9333 - val_loss: 0.4099 - val_accuracy: 0.8000\n",
      "Epoch 130/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1727 - accuracy: 0.9333 - val_loss: 0.4091 - val_accuracy: 0.8000\n",
      "Epoch 131/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1722 - accuracy: 0.9333 - val_loss: 0.4083 - val_accuracy: 0.8143\n",
      "Epoch 132/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1716 - accuracy: 0.9333 - val_loss: 0.4076 - val_accuracy: 0.8143\n",
      "Epoch 133/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1711 - accuracy: 0.9333 - val_loss: 0.4069 - val_accuracy: 0.8143\n",
      "Epoch 134/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1706 - accuracy: 0.9333 - val_loss: 0.4061 - val_accuracy: 0.8143\n",
      "Epoch 135/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1701 - accuracy: 0.9333 - val_loss: 0.4054 - val_accuracy: 0.8143\n",
      "Epoch 136/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1697 - accuracy: 0.9333 - val_loss: 0.4046 - val_accuracy: 0.8143\n",
      "Epoch 137/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1692 - accuracy: 0.9333 - val_loss: 0.4039 - val_accuracy: 0.8143\n",
      "Epoch 138/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1687 - accuracy: 0.9333 - val_loss: 0.4031 - val_accuracy: 0.8143\n",
      "Epoch 139/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1682 - accuracy: 0.9333 - val_loss: 0.4024 - val_accuracy: 0.8143\n",
      "Epoch 140/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1678 - accuracy: 0.9333 - val_loss: 0.4017 - val_accuracy: 0.8143\n",
      "Epoch 141/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1673 - accuracy: 0.9333 - val_loss: 0.4009 - val_accuracy: 0.8143\n",
      "Epoch 142/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1668 - accuracy: 0.9667 - val_loss: 0.4002 - val_accuracy: 0.8143\n",
      "Epoch 143/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1664 - accuracy: 0.9667 - val_loss: 0.3995 - val_accuracy: 0.8143\n",
      "Epoch 144/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1659 - accuracy: 0.9667 - val_loss: 0.3988 - val_accuracy: 0.8143\n",
      "Epoch 145/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1655 - accuracy: 0.9667 - val_loss: 0.3981 - val_accuracy: 0.8143\n",
      "Epoch 146/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1650 - accuracy: 0.9667 - val_loss: 0.3973 - val_accuracy: 0.8143\n",
      "Epoch 147/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1646 - accuracy: 0.9667 - val_loss: 0.3966 - val_accuracy: 0.8143\n",
      "Epoch 148/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1642 - accuracy: 0.9667 - val_loss: 0.3960 - val_accuracy: 0.8143\n",
      "Epoch 149/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1637 - accuracy: 0.9667 - val_loss: 0.3953 - val_accuracy: 0.8286\n",
      "Epoch 150/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1633 - accuracy: 0.9667 - val_loss: 0.3946 - val_accuracy: 0.8286\n",
      "Epoch 151/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1629 - accuracy: 0.9667 - val_loss: 0.3940 - val_accuracy: 0.8286\n",
      "Epoch 152/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1625 - accuracy: 0.9667 - val_loss: 0.3933 - val_accuracy: 0.8286\n",
      "Epoch 153/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1620 - accuracy: 0.9667 - val_loss: 0.3927 - val_accuracy: 0.8286\n",
      "Epoch 154/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1616 - accuracy: 0.9667 - val_loss: 0.3921 - val_accuracy: 0.8286\n",
      "Epoch 155/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1612 - accuracy: 0.9667 - val_loss: 0.3914 - val_accuracy: 0.8286\n",
      "Epoch 156/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1608 - accuracy: 0.9667 - val_loss: 0.3908 - val_accuracy: 0.8286\n",
      "Epoch 157/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1605 - accuracy: 0.9667 - val_loss: 0.3902 - val_accuracy: 0.8286\n",
      "Epoch 158/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1601 - accuracy: 0.9667 - val_loss: 0.3897 - val_accuracy: 0.8286\n",
      "Epoch 159/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1597 - accuracy: 0.9667 - val_loss: 0.3891 - val_accuracy: 0.8286\n",
      "Epoch 160/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1593 - accuracy: 0.9667 - val_loss: 0.3885 - val_accuracy: 0.8286\n",
      "Epoch 161/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1589 - accuracy: 0.9667 - val_loss: 0.3879 - val_accuracy: 0.8286\n",
      "Epoch 162/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1585 - accuracy: 0.9667 - val_loss: 0.3874 - val_accuracy: 0.8286\n",
      "Epoch 163/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1582 - accuracy: 0.9667 - val_loss: 0.3868 - val_accuracy: 0.8286\n",
      "Epoch 164/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1578 - accuracy: 0.9667 - val_loss: 0.3863 - val_accuracy: 0.8286\n",
      "Epoch 165/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1575 - accuracy: 0.9667 - val_loss: 0.3858 - val_accuracy: 0.8286\n",
      "Epoch 166/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1571 - accuracy: 0.9667 - val_loss: 0.3852 - val_accuracy: 0.8286\n",
      "Epoch 167/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1568 - accuracy: 0.9667 - val_loss: 0.3847 - val_accuracy: 0.8286\n",
      "Epoch 168/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1564 - accuracy: 0.9667 - val_loss: 0.3842 - val_accuracy: 0.8286\n",
      "Epoch 169/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1561 - accuracy: 0.9667 - val_loss: 0.3837 - val_accuracy: 0.8286\n",
      "Epoch 170/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1557 - accuracy: 0.9667 - val_loss: 0.3833 - val_accuracy: 0.8286\n",
      "Epoch 171/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1554 - accuracy: 0.9667 - val_loss: 0.3828 - val_accuracy: 0.8286\n",
      "Epoch 172/4000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1551 - accuracy: 0.9667 - val_loss: 0.3824 - val_accuracy: 0.8286\n",
      "Epoch 173/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1547 - accuracy: 0.9667 - val_loss: 0.3819 - val_accuracy: 0.8286\n",
      "Epoch 174/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1544 - accuracy: 0.9667 - val_loss: 0.3815 - val_accuracy: 0.8286\n",
      "Epoch 175/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1541 - accuracy: 0.9667 - val_loss: 0.3811 - val_accuracy: 0.8286\n",
      "Epoch 176/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1538 - accuracy: 0.9667 - val_loss: 0.3806 - val_accuracy: 0.8286\n",
      "Epoch 177/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1535 - accuracy: 0.9667 - val_loss: 0.3802 - val_accuracy: 0.8286\n",
      "Epoch 178/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1532 - accuracy: 0.9667 - val_loss: 0.3798 - val_accuracy: 0.8286\n",
      "Epoch 179/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1529 - accuracy: 0.9667 - val_loss: 0.3794 - val_accuracy: 0.8286\n",
      "Epoch 180/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1526 - accuracy: 0.9667 - val_loss: 0.3791 - val_accuracy: 0.8286\n",
      "Epoch 181/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1523 - accuracy: 0.9667 - val_loss: 0.3787 - val_accuracy: 0.8286\n",
      "Epoch 182/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1520 - accuracy: 0.9667 - val_loss: 0.3783 - val_accuracy: 0.8286\n",
      "Epoch 183/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1517 - accuracy: 0.9667 - val_loss: 0.3780 - val_accuracy: 0.8286\n",
      "Epoch 184/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1514 - accuracy: 0.9667 - val_loss: 0.3776 - val_accuracy: 0.8286\n",
      "Epoch 185/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1511 - accuracy: 0.9667 - val_loss: 0.3773 - val_accuracy: 0.8286\n",
      "Epoch 186/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1509 - accuracy: 0.9667 - val_loss: 0.3770 - val_accuracy: 0.8286\n",
      "Epoch 187/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1506 - accuracy: 0.9667 - val_loss: 0.3767 - val_accuracy: 0.8286\n",
      "Epoch 188/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1503 - accuracy: 0.9667 - val_loss: 0.3764 - val_accuracy: 0.8286\n",
      "Epoch 189/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1501 - accuracy: 0.9667 - val_loss: 0.3761 - val_accuracy: 0.8286\n",
      "Epoch 190/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1498 - accuracy: 0.9667 - val_loss: 0.3758 - val_accuracy: 0.8286\n",
      "Epoch 191/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1496 - accuracy: 0.9667 - val_loss: 0.3755 - val_accuracy: 0.8286\n",
      "Epoch 192/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1493 - accuracy: 0.9667 - val_loss: 0.3753 - val_accuracy: 0.8286\n",
      "Epoch 193/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1490 - accuracy: 0.9667 - val_loss: 0.3750 - val_accuracy: 0.8286\n",
      "Epoch 194/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1488 - accuracy: 0.9667 - val_loss: 0.3748 - val_accuracy: 0.8286\n",
      "Epoch 195/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1486 - accuracy: 0.9667 - val_loss: 0.3745 - val_accuracy: 0.8286\n",
      "Epoch 196/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1483 - accuracy: 0.9667 - val_loss: 0.3743 - val_accuracy: 0.8286\n",
      "Epoch 197/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1481 - accuracy: 0.9667 - val_loss: 0.3741 - val_accuracy: 0.8286\n",
      "Epoch 198/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1479 - accuracy: 0.9667 - val_loss: 0.3739 - val_accuracy: 0.8286\n",
      "Epoch 199/4000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1477 - accuracy: 0.9667 - val_loss: 0.3737 - val_accuracy: 0.8286\n",
      "Epoch 200/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1474 - accuracy: 0.9667 - val_loss: 0.3735 - val_accuracy: 0.8286\n",
      "Epoch 201/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1472 - accuracy: 0.9667 - val_loss: 0.3733 - val_accuracy: 0.8286\n",
      "Epoch 202/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1470 - accuracy: 0.9667 - val_loss: 0.3732 - val_accuracy: 0.8286\n",
      "Epoch 203/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1468 - accuracy: 0.9667 - val_loss: 0.3730 - val_accuracy: 0.8286\n",
      "Epoch 204/4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1466 - accuracy: 0.9667 - val_loss: 0.3729 - val_accuracy: 0.8286\n",
      "Epoch 205/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1464 - accuracy: 0.9667 - val_loss: 0.3727 - val_accuracy: 0.8286\n",
      "Epoch 206/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1462 - accuracy: 0.9667 - val_loss: 0.3726 - val_accuracy: 0.8286\n",
      "Epoch 207/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1460 - accuracy: 0.9667 - val_loss: 0.3724 - val_accuracy: 0.8286\n",
      "Epoch 208/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1458 - accuracy: 0.9667 - val_loss: 0.3723 - val_accuracy: 0.8286\n",
      "Epoch 209/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.3722 - val_accuracy: 0.8286\n",
      "Epoch 210/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1454 - accuracy: 0.9667 - val_loss: 0.3721 - val_accuracy: 0.8286\n",
      "Epoch 211/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1452 - accuracy: 0.9667 - val_loss: 0.3720 - val_accuracy: 0.8286\n",
      "Epoch 212/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1450 - accuracy: 0.9667 - val_loss: 0.3719 - val_accuracy: 0.8286\n",
      "Epoch 213/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1448 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "Epoch 214/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1447 - accuracy: 0.9667 - val_loss: 0.3718 - val_accuracy: 0.8286\n",
      "Epoch 215/4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1445 - accuracy: 0.9667 - val_loss: 0.3717 - val_accuracy: 0.8286\n",
      "Epoch 216/4000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1443 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8286\n",
      "Epoch 217/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1441 - accuracy: 0.9667 - val_loss: 0.3716 - val_accuracy: 0.8286\n",
      "Epoch 218/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1440 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8286\n",
      "Epoch 219/4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1438 - accuracy: 0.9667 - val_loss: 0.3715 - val_accuracy: 0.8143\n",
      "Epoch 220/4000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1436 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "Epoch 221/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1435 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "Epoch 222/4000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1433 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "Epoch 223/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1432 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "Epoch 224/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1430 - accuracy: 0.9667 - val_loss: 0.3714 - val_accuracy: 0.8143\n",
      "Epoch 225/4000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1429 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "Epoch 226/4000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1427 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "Epoch 227/4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1426 - accuracy: 0.9667 - val_loss: 0.3713 - val_accuracy: 0.8143\n",
      "Epoch 00227: early stopping\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.9667\n",
      "3/3 [==============================] - 0s 975us/step - loss: 0.3713 - accuracy: 0.8143\n",
      "Train: 0.967, Test: 0.814\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=1, callbacks=[es])\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=1)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping with adding a delay to the trigger in terms of the number of epochs on which we would like to see no improvement.\n",
    "#Patience = number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01071: early stopping\n",
      "Train: 1.000, Test: 0.943\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1 , patience=200)\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the best model iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64286\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64286\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.64286 to 0.68571, saving model to best_model.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.68571 to 0.70000, saving model to best_model.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.70000 to 0.71429, saving model to best_model.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.71429 to 0.72857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00063: val_accuracy improved from 0.72857 to 0.74286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00111: val_accuracy improved from 0.74286 to 0.75714, saving model to best_model.h5\n",
      "\n",
      "Epoch 00112: val_accuracy improved from 0.75714 to 0.77143, saving model to best_model.h5\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.77143\n",
      "\n",
      "Epoch 00123: val_accuracy improved from 0.77143 to 0.78571, saving model to best_model.h5\n",
      "\n",
      "Epoch 00124: val_accuracy improved from 0.78571 to 0.80000, saving model to best_model.h5\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00127: val_accuracy improved from 0.80000 to 0.81429, saving model to best_model.h5\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.81429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00146: val_accuracy improved from 0.81429 to 0.82857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00292: val_accuracy improved from 0.82857 to 0.84286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.84286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00401: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00402: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00403: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00404: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00405: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00406: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00407: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00408: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00409: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00410: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00411: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00412: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00413: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00414: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00415: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00416: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00417: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00418: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00419: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00420: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00421: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00422: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00423: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00424: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00425: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00426: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00427: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00428: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00429: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00430: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00431: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00432: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00433: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00434: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00435: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00436: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00437: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00438: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00439: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00440: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00441: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00442: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00443: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00444: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00445: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00446: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00447: val_accuracy did not improve from 0.84286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00448: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00449: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00450: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00451: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00452: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00453: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00454: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00455: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00456: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00457: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00458: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00459: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00460: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00461: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00462: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00463: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00464: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00465: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00466: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00467: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00468: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00469: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00470: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00471: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00472: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00473: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00474: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00475: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00476: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00477: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00478: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00479: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00480: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00481: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00482: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00483: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00484: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00485: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00486: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00487: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00488: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00489: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00490: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00491: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00492: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00493: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00494: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00495: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00496: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00497: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00498: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00499: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00500: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00501: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00502: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00503: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00504: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00505: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00506: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00507: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00508: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00509: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00510: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00511: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00512: val_accuracy improved from 0.84286 to 0.85714, saving model to best_model.h5\n",
      "\n",
      "Epoch 00513: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00514: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00515: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00516: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00517: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00518: val_accuracy did not improve from 0.85714\n",
      "\n",
      "Epoch 00519: val_accuracy improved from 0.85714 to 0.87143, saving model to best_model.h5\n",
      "\n",
      "Epoch 00520: val_accuracy did not improve from 0.87143\n",
      "\n",
      "Epoch 00521: val_accuracy did not improve from 0.87143\n",
      "\n",
      "Epoch 00522: val_accuracy did not improve from 0.87143\n",
      "\n",
      "Epoch 00523: val_accuracy improved from 0.87143 to 0.88571, saving model to best_model.h5\n",
      "\n",
      "Epoch 00524: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00525: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00526: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00527: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00528: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00529: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00530: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00531: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00532: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00533: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00534: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00535: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00536: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00537: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00538: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00539: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00540: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00541: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00542: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00543: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00544: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00545: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00546: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00547: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00548: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00549: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00550: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00551: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00552: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00553: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00554: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00555: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00556: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00557: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00558: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00559: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00560: val_accuracy did not improve from 0.88571\n",
      "\n",
      "Epoch 00561: val_accuracy improved from 0.88571 to 0.90000, saving model to best_model.h5\n",
      "\n",
      "Epoch 00562: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00563: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00564: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00565: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00566: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00567: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00568: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00569: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00570: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00571: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00572: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00573: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00574: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00575: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00576: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00577: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00578: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00579: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00580: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00581: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00582: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00583: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00584: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00585: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00586: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00587: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00588: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00589: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00590: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00591: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00592: val_accuracy did not improve from 0.90000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00593: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00594: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00595: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00596: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00597: val_accuracy did not improve from 0.90000\n",
      "\n",
      "Epoch 00598: val_accuracy improved from 0.90000 to 0.91429, saving model to best_model.h5\n",
      "\n",
      "Epoch 00599: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00600: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00601: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00602: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00603: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00604: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00605: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00606: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00607: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00608: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00609: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00610: val_accuracy did not improve from 0.91429\n",
      "\n",
      "Epoch 00611: val_accuracy improved from 0.91429 to 0.92857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00612: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00613: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00614: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00615: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00616: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00617: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00618: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00619: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00620: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00621: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00622: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00623: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00624: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00625: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00626: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00627: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00628: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00629: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00630: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00631: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00632: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00633: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00634: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00635: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00636: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00637: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00638: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00639: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00640: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00641: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00642: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00643: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00644: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00645: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00646: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00647: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00648: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00649: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00650: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00651: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00652: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00653: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00654: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00655: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00656: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00657: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00658: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00659: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00660: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00661: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00662: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00663: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00664: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00665: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00666: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00667: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00668: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00669: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00670: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00671: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00672: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00673: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00674: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00675: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00676: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00677: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00678: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00679: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00680: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00681: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00682: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00683: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00684: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00685: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00686: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00687: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00688: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00689: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00690: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00691: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00692: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00693: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00694: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00695: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00696: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00697: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00698: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00699: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00700: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00701: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00702: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00703: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00704: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00705: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00706: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00707: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00708: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00709: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00710: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00711: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00712: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00713: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00714: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00715: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00716: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00717: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00718: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00719: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00720: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00721: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00722: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00723: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00724: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00725: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00726: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00727: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00728: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00729: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00730: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00731: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00732: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00733: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00734: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00735: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00736: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00737: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00738: val_accuracy did not improve from 0.92857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00739: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00740: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00741: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00742: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00743: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00744: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00745: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00746: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00747: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00748: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00749: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00750: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00751: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00752: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00753: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00754: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00755: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00756: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00757: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00758: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00759: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00760: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00761: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00762: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00763: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00764: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00765: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00766: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00767: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00768: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00769: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00770: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00771: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00772: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00773: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00774: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00775: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00776: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00777: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00778: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00779: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00780: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00781: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00782: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00783: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00784: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00785: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00786: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00787: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00788: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00789: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00790: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00791: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00792: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00793: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00794: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00795: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00796: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00797: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00798: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00799: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00800: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00801: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00802: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00803: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00804: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00805: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00806: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00807: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00808: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00809: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00810: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00811: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00812: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00813: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00814: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00815: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00816: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00817: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00818: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00819: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00820: val_accuracy did not improve from 0.92857\n",
      "\n",
      "Epoch 00821: val_accuracy improved from 0.92857 to 0.94286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00822: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00823: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00824: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00825: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00826: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00827: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00828: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00829: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00830: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00831: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00832: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00833: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00834: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00835: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00836: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00837: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00838: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00839: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00840: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00841: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00842: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00843: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00844: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00845: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00846: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00847: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00848: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00849: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00850: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00851: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00852: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00853: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00854: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00855: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00856: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00857: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00858: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00859: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00860: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00861: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00862: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00863: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00864: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00865: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00866: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00867: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00868: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00869: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00870: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00871: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00872: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00873: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00874: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00875: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00876: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00877: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00878: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00879: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00880: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00881: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00882: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00883: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00884: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00885: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00886: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00887: val_accuracy did not improve from 0.94286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00888: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00889: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00890: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00891: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00892: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00893: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00894: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00895: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00896: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00897: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00898: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00899: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00900: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00901: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00902: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00903: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00904: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00905: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00906: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00907: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00908: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00909: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00910: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00911: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00912: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00913: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00914: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00915: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00916: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00917: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00918: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00919: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00920: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00921: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00922: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00923: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00924: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00925: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00926: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00927: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00928: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00929: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00930: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00931: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00932: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00933: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00934: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00935: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00936: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00937: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00938: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00939: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00940: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00941: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00942: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00943: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00944: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00945: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00946: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00947: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00948: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00949: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00950: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00951: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00952: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00953: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00954: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00955: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00956: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00957: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00958: val_accuracy did not improve from 0.94286\n",
      "\n",
      "Epoch 00959: val_accuracy did not improve from 0.94286\n",
      "Epoch 00959: early stopping\n",
      "Train: 1.000, Test: 0.943\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es, mc])\n",
    "# load the saved model\n",
    "saved_model = load_model('best_model.h5')\n",
    "# evaluate the model\n",
    "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
